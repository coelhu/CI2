{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coelhu/CI2/blob/Aula_1/atividade06_leitor_de_captcha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Atividade 06\n",
        "# Aluno: André Coelho Ramos\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sympy import true\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Images captcha salvos localmente na pasta captcha_images_v2/ dentro da pasta do projeto\n",
        "data_dir = Path(\"../input/captcha-version-2-images/samples/\")\n",
        "\n",
        "# Pega uma lista de todas as imagens\n",
        "images = list(data_dir.glob(\"*.png\"))\n",
        "print(\"Número de imagens encontradas: \", len(images))\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-08-31T23:44:37.062910Z",
          "iopub.execute_input": "2023-08-31T23:44:37.063389Z",
          "iopub.status.idle": "2023-08-31T23:44:37.124228Z",
          "shell.execute_reply.started": "2023-08-31T23:44:37.063357Z",
          "shell.execute_reply": "2023-08-31T23:44:37.123196Z"
        },
        "trusted": true,
        "id": "Md2qxlLkFRXw",
        "outputId": "f4efbee2-0b14-4afc-acde-810c8c766ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Número de imagens encontradas:  1040\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva todos os caracteres dos nomes dos captchas em um array\n",
        "characters = set()\n",
        "\n",
        "# Array para salvar o tamanho de cada captcha\n",
        "captcha_length = []\n",
        "\n",
        "# Armazena informações da imagem e seu label ou nome\n",
        "dataset = []\n",
        "\n",
        "# Armazena as informações de todas as imagens da pasta\n",
        "for img_path in images:\n",
        "    # 1. Pega o nome associado com cada imagem\n",
        "    label = img_path.name.split(\".png\")[0]\n",
        "    # 2. Salva o tamanho\n",
        "    captcha_length.append(len(label))\n",
        "    # 3. Salva a informação de imagem e label\n",
        "    dataset.append((str(img_path), label))\n",
        "    # 4. Salva os caracteres presents no label\n",
        "    for ch in label:\n",
        "        characters.add(ch)\n",
        "\n",
        "# Ordena os caracteres\n",
        "characters = sorted(characters)\n",
        "\n",
        "# Converte em dataframe o dataset\n",
        "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n",
        "\n",
        "# Mistura o dataset\n",
        "dataset = dataset.sample(frac=1.0).reset_index(drop=True)\n",
        "\n",
        "# Divide o dataset em dados de treinamento e dados de validação, com 10% para o teste\n",
        "training_data, validation_data = train_test_split(\n",
        "    dataset, test_size=0.1, random_state=seed\n",
        ")\n",
        "training_data = training_data.reset_index(drop=True)\n",
        "validation_data = validation_data.reset_index(drop=True)\n",
        "\n",
        "# Mapeia labels para números\n",
        "char_to_labels = {char: idx for idx, char in enumerate(characters)}\n",
        "\n",
        "# Mapeia labels numericos para texto\n",
        "labels_to_char = {val: key for key, val in char_to_labels.items()}\n",
        "\n",
        "\n",
        "# Função para verificar se existem imagens corrompidas\n",
        "def is_valid_captcha(captcha):\n",
        "    for ch in captcha:\n",
        "        if not ch in characters:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "#A função gera matrizes de imagens e rótulos a partir de um dataframe do pandas.\n",
        "#A função primeiro cria arrays vazios para imagens e rótulos.\n",
        "# Em seguida, ele percorre o dataframe e lê cada imagem.\n",
        "# As imagens são convertidas para tons de cinza e redimensionadas, se necessário.\n",
        "# As imagens são então normalizadas para o intervalo [0, 1].\n",
        "# Os rótulos também são convertidos em uma matriz numpy.\n",
        "def generate_arrays(df, resize=True, img_height=50, img_width=200):\n",
        "    \"\"\"Gera arrays de imagem e labels do dataframe\n",
        "\n",
        "    Args:\n",
        "        df: dataframe que queremos ler\n",
        "        resize (bool)    :  redimencionar as imagens ou não\n",
        "        img_weidth (int): largura da imagem redimencionada\n",
        "        img_height (int): altura da imagem redimencionada\n",
        "\n",
        "    Retorna:\n",
        "        images (ndarray): imagens em escala de cinza\n",
        "        labels (ndarray): labels correspondentes\n",
        "    \"\"\"\n",
        "\n",
        "    num_items = len(df)\n",
        "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
        "    labels = [0] * num_items\n",
        "\n",
        "    for i in range(num_items):\n",
        "        img = cv2.imread(df[\"img_path\"][i])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if resize:\n",
        "            img = cv2.resize(img, (img_width, img_height))\n",
        "\n",
        "        img = (img / 255.0).astype(np.float32)\n",
        "        label = df[\"label\"][i]\n",
        "\n",
        "        # Somente adiciona se é um captcha válido\n",
        "        if is_valid_captcha(label):\n",
        "            images[i, :, :] = img\n",
        "            labels[i] = label\n",
        "\n",
        "    return images, np.array(labels)\n",
        "\n",
        "\n",
        "# Constroi dados de treinamento\n",
        "training_data, training_labels = generate_arrays(df=training_data)\n",
        "\n",
        "# Constroi dados de validação\n",
        "validation_data, validation_labels = generate_arrays(df=validation_data)\n",
        "\n",
        "\n",
        "# A função DataGenerator é uma classe que gera lotes de dados para um modelo de reconhecimento captcha.\n",
        "# Para cada imagem do lote, o método:\n",
        "#   Transpõe a imagem.\n",
        "#   Adiciona uma dimensão extra à imagem.\n",
        "#   Obtém o rótulo correspondente.\n",
        "#   Inclui o par somente se o captcha for válido.\n",
        "#    Retorna:\n",
        "#        batch_inputs: um dicionario contendo entradas de batch\n",
        "#        batch_labels: um batch de labels correspondentes\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data,\n",
        "        labels,\n",
        "        char_map,\n",
        "        batch_size=16,\n",
        "        img_width=200,\n",
        "        img_height=50,\n",
        "        downsample_factor=4,\n",
        "        max_length=5,\n",
        "        shuffle=True,\n",
        "    ):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.char_map = char_map\n",
        "        self.batch_size = batch_size\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(data))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Pega o próximo batch de indices\n",
        "        curr_batch_idx = self.indices[\n",
        "            idx * self.batch_size : (idx + 1) * self.batch_size\n",
        "        ]\n",
        "\n",
        "        # 2. Isso não é necessário mas pode ajudar a alvar memória\n",
        "        # porque nem todos os batches devem ter elementos iguais ao de tamanho do batch\n",
        "        batch_len = len(curr_batch_idx)\n",
        "\n",
        "        # 3. Instancia os arrays de batchs\n",
        "        batch_images = np.ones(\n",
        "            (batch_len, self.img_width, self.img_height, 1), dtype=np.float32\n",
        "        )\n",
        "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
        "        input_length = np.ones((batch_len, 1), dtype=np.int64) * (\n",
        "            self.img_width // self.downsample_factor - 2\n",
        "        )\n",
        "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "\n",
        "        for j, idx in enumerate(curr_batch_idx):\n",
        "            # 1. Transposta a imagem\n",
        "            img = self.data[idx].T\n",
        "            # 2. Adiciona dimenção extra\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            # 3. Pega o label correspondente\n",
        "            text = self.labels[idx]\n",
        "            # 4. Inclui o par somente se o catpcha é válido\n",
        "            if is_valid_captcha(text):\n",
        "                label = [self.char_map[ch] for ch in text]\n",
        "                batch_images[j] = img\n",
        "                batch_labels[j] = label\n",
        "                label_length[j] = len(text)\n",
        "\n",
        "        batch_inputs = {\n",
        "            \"input_data\": batch_images,\n",
        "            \"input_label\": batch_labels,\n",
        "            \"input_length\": input_length,\n",
        "            \"label_length\": label_length,\n",
        "        }\n",
        "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "\n",
        "# Tamanh do batch para treino e validação\n",
        "batch_size = 16\n",
        "\n",
        "# Tamanho desejado das imagens\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "\n",
        "# Fator de downsampling da imagem por blocos convolucionais\n",
        "downsample_factor = 4\n",
        "\n",
        "# Tamanho máximo de qualquer captcha nos dados\n",
        "max_length = 5\n",
        "\n",
        "# Objeto gerador para os dados de treinamento\n",
        "train_data_generator = DataGenerator(\n",
        "    data=training_data,\n",
        "    labels=training_labels,\n",
        "    char_map=char_to_labels,\n",
        "    batch_size=batch_size,\n",
        "    img_width=img_width,\n",
        "    img_height=img_height,\n",
        "    downsample_factor=downsample_factor,\n",
        "    max_length=max_length,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Objeto gerador para os dados de validação\n",
        "valid_data_generator = DataGenerator(\n",
        "    data=validation_data,\n",
        "    labels=validation_labels,\n",
        "    char_map=char_to_labels,\n",
        "    batch_size=batch_size,\n",
        "    img_width=img_width,\n",
        "    img_height=img_height,\n",
        "    downsample_factor=downsample_factor,\n",
        "    max_length=max_length,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "\n",
        "# A função CTCLayer é uma camada Keras personalizada que calcula a perda de CTC para um modelo de\n",
        "# reconhecimento de captcha.\n",
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred, input_length, label_length):\n",
        "        # Calcula a perda do training-time e adicionar ao layer\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # Durante o teste retorna somente a perda\n",
        "        return loss\n",
        "\n",
        "\n",
        "# A função build_model() constrói um modelo de reconhecimento captcha baseado em rede neural convolucional (CNN).\n",
        "# A função primeiro define as camadas de entrada para as imagens, rótulos, comprimentos de entrada e\n",
        "# comprimentos de rótulos.\n",
        "# Em seguida, define blocos da CNN\n",
        "# A função então define blocos RNN\n",
        "def build_model():\n",
        "    # Adiciona ao modelo\n",
        "    input_img = layers.Input(\n",
        "        shape=(img_width, img_height, 1), name=\"input_data\", dtype=\"float32\"\n",
        "    )\n",
        "    labels = layers.Input(name=\"input_label\", shape=[max_length], dtype=\"float32\")\n",
        "    input_length = layers.Input(name=\"input_length\", shape=[1], dtype=\"int64\")\n",
        "    label_length = layers.Input(name=\"label_length\", shape=[1], dtype=\"int64\")\n",
        "\n",
        "    # Primeiro block convulacional\n",
        "    x = layers.Conv2D(\n",
        "        32,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv1\",\n",
        "    )(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "\n",
        "    # Segundo block convulacional\n",
        "    x = layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv2\",\n",
        "    )(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "\n",
        "    new_shape = ((img_width // 4), (img_height // 4) * 64)\n",
        "    x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.2))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
        "\n",
        "    # Precição\n",
        "    x = layers.Dense(\n",
        "        len(characters) + 1,\n",
        "        activation=\"softmax\",\n",
        "        name=\"dense2\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "    )(x)\n",
        "\n",
        "    # Calcula CTC\n",
        "    output = CTCLayer(name=\"ctc_loss\")(labels, x, input_length, label_length)\n",
        "\n",
        "    # Define o modelo\n",
        "    model = keras.models.Model(\n",
        "        inputs=[input_img, labels, input_length, label_length],\n",
        "        outputs=output,\n",
        "        name=\"ocr_model_v1\",\n",
        "    )\n",
        "\n",
        "    # Otimizar\n",
        "    sgd = keras.optimizers.SGD(\n",
        "        learning_rate=0.002, momentum=0.9, nesterov=True, clipnorm=5\n",
        "    )\n",
        "\n",
        "    # Compila o model o retorna\n",
        "    model.compile(optimizer=sgd)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Construir e imprimir um resumo do modelo de reconhecimento de captcha.\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "# Define um retorno de chamada EarlyStopping. Esse retorno de chamada interrompe o treinamento do modelo\n",
        "# antecipadamente se a perda de validação não melhorar por um determinado número de épocas (paciência).\n",
        "# Os melhores pesos do modelo são restaurados quando o callback interrompe o treinamento.\n",
        "es = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "# A função treina o modelo usando o train_data_generator e avalia o modelo usando o valid_data_generator.\n",
        "# O treinamento é feito para épocas e o retorno de chamada es é usado para interromper o\n",
        "# treinamento antecipadamente se a perda de validação não melhorar.\n",
        "history = model.fit(\n",
        "    train_data_generator,\n",
        "    validation_data=valid_data_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[es],\n",
        ")\n",
        "\n",
        "# A função cria um novo modelo que é um subconjunto do modelo original.\n",
        "# O novo modelo inclui apenas a camada de entrada e a camada densa com 46 neurônios.\n",
        "# Isso é chamado de modelo ajustado.\n",
        "prediction_model = keras.models.Model(\n",
        "    model.get_layer(name=\"input_data\").input, model.get_layer(name=\"dense2\").output\n",
        ")\n",
        "prediction_model.summary()\n",
        "\n",
        "\n",
        "# A função decodifica as previsões do modelo de reconhecimento captcha.\n",
        "# A função primeiro remove as duas últimas colunas das previsões, que não são usadas para decodificação.\n",
        "# Em seguida, ele calcula os comprimentos de entrada, que são iguais para todas as previsões.\n",
        "# A função então usa o backend Keras para decodificar as previsões usando o algoritmo de pesquisa ganancioso.\n",
        "# O algoritmo de busca ganancioso simplesmente escolhe o rótulo mais provável em cada intervalo de tempo.\n",
        "def decode_batch_predictions(pred):\n",
        "    pred = pred[:, :-2]\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "\n",
        "    # Use busca do tipo greedy search\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "\n",
        "    # Loop pelos resultados e retorna o texto\n",
        "    output_text = []\n",
        "    for res in results.numpy():\n",
        "        outstr = \"\"\n",
        "        for c in res:\n",
        "            if c < len(characters) and c >= 0:\n",
        "                outstr += labels_to_char[c]\n",
        "        output_text.append(outstr)\n",
        "\n",
        "    # Retorno os resultados finais\n",
        "    return output_text"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-08-31T23:44:37.252071Z",
          "iopub.execute_input": "2023-08-31T23:44:37.252765Z",
          "iopub.status.idle": "2023-09-01T00:00:30.212222Z",
          "shell.execute_reply.started": "2023-08-31T23:44:37.252727Z",
          "shell.execute_reply": "2023-09-01T00:00:30.211289Z"
        },
        "trusted": true,
        "id": "IakH6dntFRXx",
        "outputId": "199a58b3-5a7a-4d04-9085-7033d057d8c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"ocr_model_v1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_data (InputLayer)        [(None, 200, 50, 1)  0           []                               \n                                ]                                                                 \n                                                                                                  \n Conv1 (Conv2D)                 (None, 200, 50, 32)  320         ['input_data[0][0]']             \n                                                                                                  \n pool1 (MaxPooling2D)           (None, 100, 25, 32)  0           ['Conv1[0][0]']                  \n                                                                                                  \n Conv2 (Conv2D)                 (None, 100, 25, 64)  18496       ['pool1[0][0]']                  \n                                                                                                  \n pool2 (MaxPooling2D)           (None, 50, 12, 64)   0           ['Conv2[0][0]']                  \n                                                                                                  \n reshape (Reshape)              (None, 50, 768)      0           ['pool2[0][0]']                  \n                                                                                                  \n dense1 (Dense)                 (None, 50, 64)       49216       ['reshape[0][0]']                \n                                                                                                  \n dropout_2 (Dropout)            (None, 50, 64)       0           ['dense1[0][0]']                 \n                                                                                                  \n bidirectional_4 (Bidirectional  (None, 50, 256)     197632      ['dropout_2[0][0]']              \n )                                                                                                \n                                                                                                  \n bidirectional_5 (Bidirectional  (None, 50, 128)     164352      ['bidirectional_4[0][0]']        \n )                                                                                                \n                                                                                                  \n input_label (InputLayer)       [(None, 5)]          0           []                               \n                                                                                                  \n dense2 (Dense)                 (None, 50, 20)       2580        ['bidirectional_5[0][0]']        \n                                                                                                  \n input_length (InputLayer)      [(None, 1)]          0           []                               \n                                                                                                  \n label_length (InputLayer)      [(None, 1)]          0           []                               \n                                                                                                  \n ctc_loss (CTCLayer)            (None, 1)            0           ['input_label[0][0]',            \n                                                                  'dense2[0][0]',                 \n                                                                  'input_length[0][0]',           \n                                                                  'label_length[0][0]']           \n                                                                                                  \n==================================================================================================\nTotal params: 432,596\nTrainable params: 432,596\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/50\n59/59 [==============================] - 24s 256ms/step - loss: 22.5924 - val_loss: 16.4388\nEpoch 2/50\n59/59 [==============================] - 13s 216ms/step - loss: 16.4129 - val_loss: 16.3857\nEpoch 3/50\n59/59 [==============================] - 13s 216ms/step - loss: 16.3286 - val_loss: 16.3435\nEpoch 4/50\n59/59 [==============================] - 13s 219ms/step - loss: 16.1844 - val_loss: 16.0998\nEpoch 5/50\n59/59 [==============================] - 12s 210ms/step - loss: 16.0422 - val_loss: 16.0636\nEpoch 6/50\n59/59 [==============================] - 13s 213ms/step - loss: 15.9927 - val_loss: 16.0098\nEpoch 7/50\n59/59 [==============================] - 13s 218ms/step - loss: 15.8527 - val_loss: 15.6414\nEpoch 8/50\n59/59 [==============================] - 13s 213ms/step - loss: 15.5046 - val_loss: 15.4293\nEpoch 9/50\n59/59 [==============================] - 13s 222ms/step - loss: 15.3135 - val_loss: 15.2974\nEpoch 10/50\n59/59 [==============================] - 13s 214ms/step - loss: 15.0805 - val_loss: 14.9722\nEpoch 11/50\n59/59 [==============================] - 13s 217ms/step - loss: 14.8404 - val_loss: 14.4724\nEpoch 12/50\n59/59 [==============================] - 13s 219ms/step - loss: 14.4665 - val_loss: 14.2377\nEpoch 13/50\n59/59 [==============================] - 13s 214ms/step - loss: 14.2461 - val_loss: 13.9972\nEpoch 14/50\n59/59 [==============================] - 13s 219ms/step - loss: 14.0220 - val_loss: 13.7802\nEpoch 15/50\n59/59 [==============================] - 12s 208ms/step - loss: 13.7539 - val_loss: 13.5913\nEpoch 16/50\n59/59 [==============================] - 13s 222ms/step - loss: 13.4642 - val_loss: 13.4539\nEpoch 17/50\n59/59 [==============================] - 13s 220ms/step - loss: 13.1911 - val_loss: 12.9378\nEpoch 18/50\n59/59 [==============================] - 13s 214ms/step - loss: 12.9034 - val_loss: 12.8797\nEpoch 19/50\n59/59 [==============================] - 13s 221ms/step - loss: 12.5574 - val_loss: 12.2211\nEpoch 20/50\n59/59 [==============================] - 13s 213ms/step - loss: 12.1502 - val_loss: 11.8958\nEpoch 21/50\n59/59 [==============================] - 13s 219ms/step - loss: 11.7197 - val_loss: 11.4806\nEpoch 22/50\n59/59 [==============================] - 13s 224ms/step - loss: 11.2445 - val_loss: 11.1080\nEpoch 23/50\n59/59 [==============================] - 13s 219ms/step - loss: 10.7827 - val_loss: 10.3371\nEpoch 24/50\n59/59 [==============================] - 13s 221ms/step - loss: 10.1175 - val_loss: 9.3865\nEpoch 25/50\n59/59 [==============================] - 13s 218ms/step - loss: 8.9623 - val_loss: 7.7335\nEpoch 26/50\n59/59 [==============================] - 13s 219ms/step - loss: 7.2837 - val_loss: 6.0692\nEpoch 27/50\n59/59 [==============================] - 13s 222ms/step - loss: 5.9919 - val_loss: 4.8553\nEpoch 28/50\n59/59 [==============================] - 13s 214ms/step - loss: 5.0918 - val_loss: 4.1781\nEpoch 29/50\n59/59 [==============================] - 13s 215ms/step - loss: 4.3795 - val_loss: 3.5340\nEpoch 30/50\n59/59 [==============================] - 13s 215ms/step - loss: 3.8031 - val_loss: 3.0548\nEpoch 31/50\n59/59 [==============================] - 13s 215ms/step - loss: 3.3650 - val_loss: 2.5765\nEpoch 32/50\n59/59 [==============================] - 13s 220ms/step - loss: 2.9923 - val_loss: 2.4340\nEpoch 33/50\n59/59 [==============================] - 13s 212ms/step - loss: 2.6008 - val_loss: 2.0570\nEpoch 34/50\n59/59 [==============================] - 13s 215ms/step - loss: 2.3486 - val_loss: 1.7948\nEpoch 35/50\n59/59 [==============================] - 12s 209ms/step - loss: 1.9697 - val_loss: 1.4727\nEpoch 36/50\n59/59 [==============================] - 13s 218ms/step - loss: 1.8600 - val_loss: 1.4802\nEpoch 37/50\n59/59 [==============================] - 12s 211ms/step - loss: 1.6728 - val_loss: 1.3723\nEpoch 38/50\n59/59 [==============================] - 13s 217ms/step - loss: 1.4937 - val_loss: 1.7486\nEpoch 39/50\n59/59 [==============================] - 13s 214ms/step - loss: 1.3527 - val_loss: 1.2785\nEpoch 40/50\n59/59 [==============================] - 13s 220ms/step - loss: 1.2350 - val_loss: 1.0178\nEpoch 41/50\n59/59 [==============================] - 13s 214ms/step - loss: 1.0930 - val_loss: 1.0322\nEpoch 42/50\n59/59 [==============================] - 13s 221ms/step - loss: 1.0062 - val_loss: 0.9846\nEpoch 43/50\n59/59 [==============================] - 13s 220ms/step - loss: 1.1234 - val_loss: 0.8432\nEpoch 44/50\n59/59 [==============================] - 13s 214ms/step - loss: 0.9751 - val_loss: 0.9159\nEpoch 45/50\n59/59 [==============================] - 13s 223ms/step - loss: 0.8379 - val_loss: 0.8415\nEpoch 46/50\n59/59 [==============================] - 13s 214ms/step - loss: 0.8402 - val_loss: 0.6988\nEpoch 47/50\n59/59 [==============================] - 12s 211ms/step - loss: 0.6873 - val_loss: 0.6464\nEpoch 48/50\n59/59 [==============================] - 13s 221ms/step - loss: 0.6294 - val_loss: 0.6514\nEpoch 49/50\n59/59 [==============================] - 13s 213ms/step - loss: 0.6859 - val_loss: 0.5164\nEpoch 50/50\n59/59 [==============================] - 13s 222ms/step - loss: 0.6140 - val_loss: 0.6923\nModel: \"model_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_data (InputLayer)     [(None, 200, 50, 1)]      0         \n                                                                 \n Conv1 (Conv2D)              (None, 200, 50, 32)       320       \n                                                                 \n pool1 (MaxPooling2D)        (None, 100, 25, 32)       0         \n                                                                 \n Conv2 (Conv2D)              (None, 100, 25, 64)       18496     \n                                                                 \n pool2 (MaxPooling2D)        (None, 50, 12, 64)        0         \n                                                                 \n reshape (Reshape)           (None, 50, 768)           0         \n                                                                 \n dense1 (Dense)              (None, 50, 64)            49216     \n                                                                 \n dropout_2 (Dropout)         (None, 50, 64)            0         \n                                                                 \n bidirectional_4 (Bidirectio  (None, 50, 256)          197632    \n nal)                                                            \n                                                                 \n bidirectional_5 (Bidirectio  (None, 50, 128)          164352    \n nal)                                                            \n                                                                 \n dense2 (Dense)              (None, 50, 20)            2580      \n                                                                 \n=================================================================\nTotal params: 432,596\nTrainable params: 432,596\nNon-trainable params: 0\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTA SOMENTE UMA IMAGEM> 8n5p3.png\n",
        "\n",
        "USANDO CÓDIGO PRÉVIO, PORÉM ADAPTADO ELE PARA SOMENTE UMA IMAGEM"
      ],
      "metadata": {
        "id": "jctxFZQKFRXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_single = list(data_dir.glob(\"8n5p3.png\"))\n",
        "print(\"Number of images found: \", len(images_single))\n",
        "\n",
        "characters_simples = set()\n",
        "captcha_length_simples = []\n",
        "dataset_simples = []\n",
        "for img_path in images_single:\n",
        "    label = img_path.name.split(\".png\")[0]\n",
        "    captcha_length_simples.append(len(label))\n",
        "    dataset_simples.append((str(img_path), label))\n",
        "    for ch in label:\n",
        "        characters_simples.add(ch)\n",
        "\n",
        "characters_simples = sorted(characters_simples)\n",
        "dataset_simples = pd.DataFrame(\n",
        "    dataset_simples, columns=[\"img_path\", \"label\"], index=None\n",
        ")\n",
        "\n",
        "validation_data_simples, validation_labels_simples = generate_arrays(df=dataset_simples)\n",
        "\n",
        "# Gera um objeto gerador para essa única imagem\n",
        "imagen_teste = DataGenerator(\n",
        "    data=validation_data_simples,\n",
        "    labels=validation_labels_simples,\n",
        "    char_map=char_to_labels,\n",
        "    batch_size=1,\n",
        "    img_width=img_width,\n",
        "    img_height=img_height,\n",
        "    downsample_factor=downsample_factor,\n",
        "    max_length=max_length,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# executa somente uma interação para pegar essa imagem e analisar ela\n",
        "for p, (inp_value, _) in enumerate(imagen_teste):\n",
        "    bs = inp_value[\"input_data\"].shape[0]\n",
        "    X_data = inp_value[\"input_data\"]\n",
        "    labels = inp_value[\"input_label\"]\n",
        "\n",
        "    preds = prediction_model.predict(X_data)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "    orig_texts = []\n",
        "    for label in labels:\n",
        "        text = \"\".join([labels_to_char[int(x)] for x in label])\n",
        "        orig_texts.append(text)\n",
        "\n",
        "    for i in range(bs):\n",
        "        print(f\"Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}\")\n",
        "    break\n",
        "\n",
        "####################################################\n",
        "## RESULTADO\n",
        "# O código consegue reconhecer a imagem 8n5p3.png\n",
        "####################################################\n",
        "\n",
        "# Ground truth: 8n5p3      Predicted: 8n5p3"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-09-01T00:00:30.214548Z",
          "iopub.execute_input": "2023-09-01T00:00:30.215331Z",
          "iopub.status.idle": "2023-09-01T00:00:31.935704Z",
          "shell.execute_reply.started": "2023-09-01T00:00:30.215298Z",
          "shell.execute_reply": "2023-09-01T00:00:31.934814Z"
        },
        "trusted": true,
        "id": "6otTOkVtFRXz",
        "outputId": "07ece203-40be-40ac-a6ef-5339cd150e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of images found:  1\n1/1 [==============================] - 2s 2s/step\nGround truth: 8n5p3 \t Predicted: 8n5p3\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}